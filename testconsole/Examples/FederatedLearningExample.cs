using System;
using System.Collections.Generic;
using System.Threading.Tasks;
using System.IO;
using System.Linq;
using AiDotNet.LinearAlgebra;
using AiDotNet.Models;
using AiDotNet.FederatedLearning;
using AiDotNet.FederatedLearning.Client;
using AiDotNet.FederatedLearning.Server;
using AiDotNet.FederatedLearning.Aggregation;
using AiDotNet.FederatedLearning.Privacy;
using AiDotNet.FederatedLearning.Communication;
using AiDotNet.FederatedLearning.MetaLearning;
using AiDotNet.Interfaces;
using AiDotNet.Enums;
using AiDotNet.Extensions;

namespace AiDotNet.Examples
{
    /// <summary>
    /// Example demonstrating federated learning with secure aggregation and differential privacy
    /// </summary>
    public class FederatedLearningExample
    {
        /// <summary>
        /// Run federated learning example
        /// </summary>
        public static async Task RunFederatedLearningExampleAsync()
        {
            Console.WriteLine("=== Federated Learning Example ===");
            Console.WriteLine();

            // Step 1: Setup federated server
            Console.WriteLine("1. Setting up federated server...");
            var server = new FederatedServer("FedServer-001")
            {
                TotalRounds = 10,
                MinimumClients = 2,
                ClientSamplingRate = 0.8,
                ConvergenceThreshold = 1e-4
            };

            // Configure privacy settings
            server.PrivacySettings = new PrivacySettings
            {
                UseDifferentialPrivacy = true,
                Epsilon = 1.0,
                Delta = 1e-5,
                ClippingThreshold = 1.0,
                NoiseMultiplier = 1.1
            };

            // Step 2: Create simulated clients
            Console.WriteLine("2. Creating federated clients...");
            var clients = CreateSimulatedClients(5);

            // Register clients with server
            foreach (var client in clients)
            {
                var clientInfo = new ClientInfo
                {
                    ClientId = client.ClientId,
                    Status = ClientConnectionStatus.Connected,
                    DataSize = client.DataSize,
                    ClientVersion = "1.0",
                    Metadata = new Dictionary<string, object> { ["region"] = "us-west" }
                };
                server.RegisterClient(client.ClientId, clientInfo);
                server.SetClientWeight(client.ClientId, client.DataSize);
            }

            // Step 3: Initialize global model
            Console.WriteLine("3. Initializing global model...");
            var parameterShapes = new Dictionary<string, int[]>
            {
                ["weights"] = new[] { 10, 5 },
                ["bias"] = new[] { 5 }
            };
            server.InitializeGlobalModel(parameterShapes);

            // Step 4: Run federated training
            Console.WriteLine("4. Starting federated training...");
            var trainingResult = await server.StartFederatedLearningAsync();

            // Step 5: Display results
            Console.WriteLine("5. Federated training completed!");
            Console.WriteLine($"   Total rounds: {trainingResult.TotalRounds}");
            Console.WriteLine($"   Training time: {trainingResult.TrainingTime.TotalSeconds:F2} seconds");
            Console.WriteLine($"   Final convergence: {trainingResult.ConvergenceHistory.LastOrDefault():E6}");
            Console.WriteLine();

            // Step 6: Display server statistics
            var serverStats = server.GetStatistics();
            Console.WriteLine("Server Statistics:");
            Console.WriteLine($"   Active clients: {serverStats.ActiveClients}");
            Console.WriteLine($"   Average round time: {serverStats.AverageRoundTime.TotalSeconds:F2} seconds");
            Console.WriteLine();

            // Step 7: Demonstrate secure aggregation
            await DemonstrateSecureAggregation();

            // Step 8: Demonstrate MAML federated learning
            await DemonstrateMAMLFederated();

            Console.WriteLine("Federated learning example completed successfully!");
        }

        /// <summary>
        /// Create simulated federated clients
        /// </summary>
        /// <param name="numClients">Number of clients to create</param>
        /// <returns>List of federated clients</returns>
        private static List<FederatedClient> CreateSimulatedClients(int numClients)
        {
            var clients = new List<FederatedClient>();
            var random = new Random(42); // Reproducible results

            for (int i = 0; i < numClients; i++)
            {
                var clientId = $"Client-{i + 1:D3}";
                
                // Create simulated local data (different distributions for heterogeneity)
                var dataSize = random.Next(100, 500);
                var featureSize = 10;
                
                var localData = GenerateSimulatedData(dataSize, featureSize, i, random);
                var localLabels = GenerateSimulatedLabels(dataSize, i, random);
                
                // Create a simple model for each client
                var localModel = new SimpleLinearModel(featureSize);
                
                var client = new FederatedClient(clientId, localModel, localData, localLabels)
                {
                    LocalEpochs = 3,
                    BatchSize = 32
                };

                clients.Add(client);
            }

            return clients;
        }

        /// <summary>
        /// Generate simulated training data with client-specific distributions
        /// </summary>
        /// <param name="dataSize">Number of samples</param>
        /// <param name="featureSize">Number of features</param>
        /// <param name="clientIndex">Client index for distribution variation</param>
        /// <param name="random">Random number generator</param>
        /// <returns>Simulated data matrix</returns>
        private static Matrix<double> GenerateSimulatedData(int dataSize, int featureSize, int clientIndex, Random random)
        {
            var data = new double[dataSize, featureSize];
            
            // Add client-specific bias to create non-IID data
            var clientBias = clientIndex * 0.5;
            
            for (int i = 0; i < dataSize; i++)
            {
                for (int j = 0; j < featureSize; j++)
                {
                    // Generate data with client-specific distribution
                    data[i, j] = random.NextGaussian(clientBias, 1.0);
                }
            }

            return new Matrix<double>(data);
        }

        /// <summary>
        /// Generate simulated labels
        /// </summary>
        /// <param name="dataSize">Number of samples</param>
        /// <param name="clientIndex">Client index</param>
        /// <param name="random">Random number generator</param>
        /// <returns>Simulated labels</returns>
        private static Vector<double> GenerateSimulatedLabels(int dataSize, int clientIndex, Random random)
        {
            var labels = new double[dataSize];
            
            for (int i = 0; i < dataSize; i++)
            {
                // Generate binary labels with client-specific bias
                var probability = 0.5 + (clientIndex % 2 == 0 ? 0.1 : -0.1);
                labels[i] = random.NextDouble() < probability ? 1.0 : 0.0;
            }

            return new Vector<double>(labels);
        }

        /// <summary>
        /// Demonstrate secure aggregation
        /// </summary>
        private static async Task DemonstrateSecureAggregation()
        {
            Console.WriteLine();
            Console.WriteLine("=== Secure Aggregation Demonstration ===");
            
            var secureAggregator = new SecureAggregation();
            var clientIds = new List<string> { "Client-A", "Client-B", "Client-C" };
            
            // Setup secure aggregation
            var publicKeys = secureAggregator.SetupSecureAggregation(clientIds);
            Console.WriteLine($"Generated public keys for {publicKeys.Count} clients");
            
            // Simulate client updates
            var clientUpdates = new Dictionary<string, Dictionary<string, Vector<double>>>();
            var random = new Random();
            
            foreach (var clientId in clientIds)
            {
                var parameters = new Dictionary<string, Vector<double>>
                {
                    ["weights"] = new Vector<double>(Enumerable.Range(0, 10).Select(_ => random.NextGaussian()).ToArray()),
                    ["bias"] = new Vector<double>(Enumerable.Range(0, 5).Select(_ => random.NextGaussian()).ToArray())
                };
                
                // Encrypt parameters for secure aggregation
                var encryptedParams = secureAggregator.EncryptClientParameters(clientId, parameters);
                clientUpdates[clientId] = encryptedParams;
            }
            
            // Perform secure aggregation
            var clientWeights = clientIds.ToDictionary(id => id, _ => 1.0);
            var aggregated = secureAggregator.AggregateParameters(
                clientUpdates, 
                clientWeights, 
                FederatedAggregationStrategy.SecureAggregation);
            
            Console.WriteLine($"Securely aggregated parameters from {clientUpdates.Count} clients");
            Console.WriteLine($"Aggregated weights shape: {aggregated["weights"].Length}");
            Console.WriteLine($"Aggregated bias shape: {aggregated["bias"].Length}");
            
            await Task.CompletedTask;
        }

        /// <summary>
        /// Demonstrate MAML federated learning
        /// </summary>
        private static async Task DemonstrateMAMLFederated()
        {
            Console.WriteLine();
            Console.WriteLine("=== MAML Federated Learning Demonstration ===");
            
            // Create meta-model
            var metaModel = new SimpleLinearModel(10);
            
            // Setup MAML parameters
            var mamlParams = new MAMLParameters
            {
                InnerLearningRate = 0.01,
                OuterLearningRate = 0.001,
                InnerSteps = 5,
                SupportSize = 10,
                QuerySize = 20
            };
            
            var mamlFederated = new MAMLFederated(metaModel, mamlParams);
            
            // Create federated tasks for clients
            var clientIds = new List<string> { "Task-Client-1", "Task-Client-2", "Task-Client-3" };
            var random = new Random(123);
            
            foreach (var clientId in clientIds)
            {
                var task = new FederatedTask
                {
                    TaskId = clientId,
                    TaskType = "BinaryClassification",
                    SupportSet = GenerateSimulatedData(mamlParams.SupportSize, 10, 0, random),
                    SupportLabels = GenerateSimulatedLabels(mamlParams.SupportSize, 0, random),
                    QuerySet = GenerateSimulatedData(mamlParams.QuerySize, 10, 0, random),
                    QueryLabels = GenerateSimulatedLabels(mamlParams.QuerySize, 0, random)
                };
                
                mamlFederated.RegisterClientTask(clientId, task);
            }
            
            // Perform meta-learning rounds
            for (int round = 0; round < 3; round++)
            {
                Console.WriteLine($"Meta-learning round {round + 1}");
                var result = await mamlFederated.PerformMetaLearningRoundAsync(clientIds);
                
                Console.WriteLine($"   Participating clients: {result.ParticipatingClients.Count}");
                Console.WriteLine($"   Average task loss: {result.AverageTaskLoss:F6}");
                Console.WriteLine($"   Meta-gradient norm: {result.MetaGradientNorm:F6}");
            }
            
            Console.WriteLine("MAML federated learning demonstration completed");
        }
    }

    /// <summary>
    /// Simple linear model for demonstration
    /// </summary>
    public class SimpleLinearModel : IFullModel<double, Vector<double>, double>
    {
        private Vector<double> _weights;
        private Vector<double> _bias;
        private HashSet<int> _activeFeatures;
        
        public SimpleLinearModel(int inputSize)
        {
            var random = new Random();
            _weights = new Vector<double>(Enumerable.Range(0, inputSize).Select(_ => random.NextGaussian(0, 0.1)).ToArray());
            _bias = new Vector<double>(new[] { random.NextGaussian(0, 0.1) });
            _activeFeatures = new HashSet<int>(Enumerable.Range(0, inputSize));
        }
        
        // IModel implementation
        public void Train(Vector<double> input, double expectedOutput)
        {
            // Simple gradient descent update
            var prediction = Predict(input);
            var error = prediction - expectedOutput;
            var learningRate = 0.01;
            
            // Update weights
            for (int i = 0; i < _weights.Length; i++)
            {
                _weights[i] -= learningRate * error * input[i];
            }
            
            // Update bias
            _bias[0] -= learningRate * error;
        }
        
        public double Predict(Vector<double> input)
        {
            var logit = _weights.DotProduct(input) + _bias[0];
            return 1.0 / (1.0 + Math.Exp(-logit)); // Sigmoid activation
        }
        
        public ModelMetaData<double> GetModelMetaData()
        {
            return new ModelMetaData<double>
            {
                ModelType = ModelType.Classification,
                FeatureCount = _weights.Length,
                Complexity = _weights.Length + 1, // weights + bias
                Description = "Simple linear model with sigmoid activation for binary classification",
                AdditionalInfo = new Dictionary<string, object>
                {
                    ["activation"] = "sigmoid",
                    ["parameters"] = _weights.Length + 1
                }
            };
        }
        
        // IModelSerializer implementation
        public byte[] Serialize()
        {
            using (var stream = new MemoryStream())
            using (var writer = new BinaryWriter(stream))
            {
                // Write weights length
                writer.Write(_weights.Length);
                
                // Write weights
                foreach (var w in _weights)
                {
                    writer.Write(w);
                }
                
                // Write bias
                writer.Write(_bias[0]);
                
                // Write active features count
                writer.Write(_activeFeatures.Count);
                
                // Write active features
                foreach (var feature in _activeFeatures)
                {
                    writer.Write(feature);
                }
                
                return stream.ToArray();
            }
        }
        
        public void Deserialize(byte[] data)
        {
            using (var stream = new MemoryStream(data))
            using (var reader = new BinaryReader(stream))
            {
                // Read weights length
                int weightsLength = reader.ReadInt32();
                
                // Read weights
                var weights = new double[weightsLength];
                for (int i = 0; i < weightsLength; i++)
                {
                    weights[i] = reader.ReadDouble();
                }
                _weights = new Vector<double>(weights);
                
                // Read bias
                _bias = new Vector<double>(new[] { reader.ReadDouble() });
                
                // Read active features count
                int activeCount = reader.ReadInt32();
                
                // Read active features
                _activeFeatures = new HashSet<int>();
                for (int i = 0; i < activeCount; i++)
                {
                    _activeFeatures.Add(reader.ReadInt32());
                }
            }
        }
        
        // IParameterizable implementation
        public Vector<double> GetParameters()
        {
            // Combine weights and bias into a single vector
            var parameters = new double[_weights.Length + 1];
            Array.Copy(_weights.ToArray(), 0, parameters, 0, _weights.Length);
            parameters[_weights.Length] = _bias[0];
            return new Vector<double>(parameters);
        }
        
        public void SetParameters(Vector<double> parameters)
        {
            if (parameters.Length != _weights.Length + 1)
            {
                throw new ArgumentException($"Expected {_weights.Length + 1} parameters, but got {parameters.Length}");
            }
            
            // Extract weights
            var weights = new double[_weights.Length];
            Array.Copy(parameters.ToArray(), 0, weights, 0, _weights.Length);
            _weights = new Vector<double>(weights);
            
            // Extract bias
            _bias = new Vector<double>(new[] { parameters[_weights.Length] });
        }
        
        public IFullModel<double, Vector<double>, double> WithParameters(Vector<double> parameters)
        {
            var model = new SimpleLinearModel(_weights.Length);
            model.SetParameters(parameters);
            model._activeFeatures = new HashSet<int>(_activeFeatures);
            return model;
        }
        
        // IFeatureAware implementation
        public IEnumerable<int> GetActiveFeatureIndices()
        {
            return _activeFeatures;
        }
        
        public bool IsFeatureUsed(int featureIndex)
        {
            return _activeFeatures.Contains(featureIndex);
        }
        
        public void SetActiveFeatureIndices(IEnumerable<int> featureIndices)
        {
            _activeFeatures = new HashSet<int>(featureIndices);
        }
        
        // ICloneable implementation
        public IFullModel<double, Vector<double>, double> DeepCopy()
        {
            var copy = new SimpleLinearModel(_weights.Length);
            copy._weights = new Vector<double>(_weights.ToArray());
            copy._bias = new Vector<double>(_bias.ToArray());
            copy._activeFeatures = new HashSet<int>(_activeFeatures);
            return copy;
        }
        
        public IFullModel<double, Vector<double>, double> Clone()
        {
            return DeepCopy();
        }
    }
}

namespace System.Linq
{
    /// <summary>
    /// Extension methods for LINQ compatibility
    /// </summary>
    public static class LinqExtensions
    {
        public static T LastOrDefault<T>(this IEnumerable<T> source)
        {
            if (source == null) return default(T);
            
            var list = source as IList<T>;
            if (list != null)
            {
                return list.Count > 0 ? list[list.Count - 1] : default(T);
            }
            
            T last = default(T);
            foreach (var item in source)
            {
                last = item;
            }
            return last;
        }
        
        public static Dictionary<TKey, TValue> ToDictionary<TSource, TKey, TValue>(
            this IEnumerable<TSource> source,
            Func<TSource, TKey> keySelector,
            Func<TSource, TValue> valueSelector) where TKey : notnull
        {
            var dictionary = new Dictionary<TKey, TValue>();
            foreach (var item in source)
            {
                dictionary[keySelector(item)] = valueSelector(item);
            }
            return dictionary;
        }
    }
}